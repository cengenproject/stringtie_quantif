# Analyze str_q results
# 


# First need to run STAR alignment (bsn9), use ref (no novel discovery), StringTie2 (str_q)
# Note we preferentially use the summary in TPM, rather than those generated by prepDE.py



## Initializations ----

suppressPackageStartupMessages({
  library(tidyverse)
})

library(wbData)
gids <- wb_load_gene_ids(281)


# load data ----

# From summarize_stringtie_output.R

transcripts_table <- read_tsv("data/220128_str_q_summaries/transcripts_table.tsv",
                              col_types = cols(seqnames = col_factor(c("I", "II","III","IV","V","X","MtDNA")),
                                               start = col_integer(),
                                               end = col_integer(),
                                               strand = col_factor(c("+","-")),
                                               gene_id = col_character(),
                                               transcript_id = col_character(),
                                               gene_name = col_character()))

stop_for_problems(transcripts_table)
transcripts_table <- transcripts_table |>
  left_join(gids |> select(-symbol, -X, -status, -name),
            by = c("gene_id"))


samples_table <- read_tsv("data/220128_str_q_summaries/samples_table.tsv",
                          col_types = "cc")
stop_for_problems(samples_table)

tx_tpm <- read_tsv("data/220128_str_q_summaries/tx_TPM.tsv")


tx_long <- read_tsv("data/220128_str_q_summaries/tx_long.tsv") |>
  left_join(transcripts_table, by = "transcript_id") |>
  left_join(samples_table, by = "sample_id")

# # export for Shiny
# t_exp <- tx_long |>
#   select(transcript_id, gene_id, sample_id, neuron_id, TPM)
# 
# write_tsv(t_exp, "data/220128_str_q_summaries/t_exp.tsv")
tx_long <- read_tsv("data/220128_str_q_summaries/t_exp.tsv",
                    col_types = cols(transcript_id = col_factor(),
                                     gene_id = col_factor(),
                                     sample_id = col_factor(),
                                     neuron_id = col_factor(),
                                     TPM = col_double()))



my_gene <- "nlg-1"





pct <- \(...) scales::number(..., suffix = "%")

ind_graph <- tx_long |>
  filter(gene_id == s2i(my_gene,gids)) |>
  group_by(transcript_id, neuron_id) |>
  summarize(mean_cnt = mean(TPM),
            sd_cnt = sd(TPM),
            .groups = "drop") |>
  group_by(neuron_id) |>
  mutate(prop = round(100*mean_cnt/sum(mean_cnt), 1),
         sd = sd_cnt/sum(mean_cnt)) |>
  rename(Neuron = neuron_id,
         Transcript = transcript_id,
         `Transcript Usage` = prop) |>
  ggplot(aes(x=Neuron,y=`Transcript Usage`, fill = Transcript)) +
  geom_col(position = position_stack()) +
  # geom_errorbar(aes(ymin=prop,ymax=prop+sd), position = position_stack()) +
  theme_classic() +
  coord_flip() +
  labs(x=NULL,y=NULL,title=my_gene) +
  # hues::scale_fill_iwanthue() +
  # ggsci::scale_fill_npg() +
  guides(fill=guide_legend(title=my_gene)) +
  scale_y_continuous(labels = pct) +
  ggsci::scale_fill_d3("category20")

plotly::ggplotly(ind_graph)





# Ordered


order_neurs <- function(transcript_id, neuron_id, prop){
  yy <- matrix(prop, byrow = TRUE,
               nrow = length(unique(transcript_id)),
               ncol = length(unique(neuron_id)),
               dimnames = list(unique(transcript_id), unique(neuron_id)))
  
  hclust(dist(t(yy)))$order
}

tx_long |>
  filter(gene_id == s2i(my_gene,gids)) |>
  group_by(transcript_id, neuron_id) |>
  summarize(mean_cnt = mean(TPM),
            sd_cnt = sd(TPM),
            .groups = "drop") |>
  group_by(neuron_id) |>
  mutate(prop = mean_cnt/sum(mean_cnt),
         sd = sd_cnt/sum(mean_cnt)) |>
  ungroup() |>
  mutate(order = pmap_int(list(transcript_id, neuron_id, prop), order_neurs),
         neuron_id = fct_reorder(neuron_id, order)) |>
  ggplot(aes(x=neuron_id,y=prop, fill = transcript_id)) +
  geom_col(position = position_stack()) +
  # geom_errorbar(aes(ymin=prop,ymax=prop+sd), position = position_stack()) +
  theme_classic() +
  coord_flip() +
  labs(x=NULL,y=NULL,title=my_gene) +
  # hues::scale_fill_iwanthue() +
  # ggsci::scale_fill_npg() +
  guides(fill=guide_legend(title="Transcript")) +
  scale_y_continuous(labels = scales::percent) +
  ggsci::scale_fill_d3("category20")



# Heatmap ----


my_genes <- s2i(c("ric-4","nlg-1"), gids)
my_neurons <- unique(tx_long$neuron_id)



tx_long |>
  filter(gene_id %in% my_genes,
         neuron_id %in% my_neurons) |>
  ggplot() +
  geom_tile(aes(x = neuron_id,
                y = transcript_id,
                fill = log1p(TPM)))



# ht <- tx_long |>
#   filter(gene_id %in% my_genes,
#          neuron_id %in% my_neurons) |>
#   mutate(gene_id = i2s(gene_id, gids)) |>
#   group_by(gene_id, transcript_id, neuron_id) |>
#   summarize(mean_tpm = mean(TPM)) |>
#   group_by(gene_id) |>
#   tidyHeatmap::heatmap(transcript_id, neuron_id, mean_tpm,
#                        transform = log1p, .scale = "none",
#                        cluster_columns=FALSE,
#                        cluster_rows = FALSE)
# 
# InteractiveComplexHeatmap::htShiny(ht)


mtcars_tidy <- 
  mtcars %>% 
  as_tibble(rownames="Car name") %>% 
  mutate_at(vars(-`Car name`, -hp, -vs), scale) %>%
  pivot_longer(cols = -c(`Car name`, hp, vs), names_to = "Property", values_to = "Value")

mtcars_heatmap <- 
  mtcars_tidy %>% 
  heatmap(`Car name`, Property, Value ) %>%
  add_tile(hp)

htShiny(mtcars_heatmap)








# _____________ ----





# # DB vs dplyr ----
# # Result: typically slower than dplyr, not worth it here
# # create DB
# library(DBI)
# con <- dbConnect(RSQLite::SQLite(), ":memory:")
# dbWriteTable(con, "tpm", tx_long)
# dbListFields(con, "tpm")
# 
# 
# get_dplyr <- function(my_gene){
#   tx_long |>
#     filter(gene_id == s2i(my_gene,gids))
# }
# 
# get_rsqlite <- function(my_gene){
#   res <- dbSendQuery(con, paste0("SELECT * FROM tpm WHERE gene_id = '",s2i(my_gene,gids),"'"))
#   yy <- dbFetch(res)
#   dbClearResult(res)
#   yy
# }
# 
# bench::mark(
#   dplyr = get_dplyr(my_gene) |> as.data.frame() |> mutate(across(where(is.factor), as.character)),
#   sqlite = get_rsqlite(my_gene))
# 
# 
# get_dplyr <- function(my_gene){
#   tx_long |>
#     filter(gene_id == s2i(my_gene,gids)) |>
#     group_by(transcript_id, neuron_id) |>
#     summarize(mean_cnt = mean(TPM),
#               .groups = "drop")
# }
# 
# 
# get_rsqlite <- function(my_gene){
#   res <- dbSendQuery(con, paste0("SELECT transcript_id, neuron_id, AVG(TPM) AS mean_cnt FROM tpm
#                                     WHERE gene_id = '",s2i(my_gene,gids),"'
#                                     GROUP BY transcript_id, neuron_id;"))
#   yy <- dbFetch(res) |>
#     as_tibble()
#   dbClearResult(res)
#   yy
# }
# 
# bench::mark(
#   dplyr = get_dplyr(my_gene),
#   sqlite = get_rsqlite(my_gene), check = FALSE)








## Prepare Data ----

# From prepDE.py

gene_cnts <- readr::read_csv("data/220128_str_q_summaries/gene_count_matrix.csv",
                        col_types = cols(gene_id = col_character(),
                                         .default = col_integer()))


tx_cnts <- readr::read_csv("data/220128_str_q_summaries/transcript_count_matrix.csv",
                           col_types = cols(transcript_id = col_character(),
                                            .default = col_integer()))



cnts_long <- tx_cnts |>
  pivot_longer(-transcript_id,
               names_to = "sample_id",
               values_to = "count")




# Check match btw tx and gene tables ----

xx <- str_match(tx_cnts$transcript_id,
          "^([A-Z0-9cel_]{1,9}\\.t?[0-9]{1,4})[a-z]?\\.?[0-9]{0,2}")

# cbind(tx_cnts$transcript_id, xx) |> View()

yy <- wb_seq2id(xx[,2], gids, warn_missing = TRUE)

xx[which(is.na(yy)),]


i2s(gene_cnts$gene_id[which(! gene_cnts$gene_id %in% yy)], gids)
#> the usual suspects: tin-9.2, unc-17, lev-10


tx_cnts |>
  mutate(gene_id = yy) |>
  select(-transcript_id) |>
  group_by(gene_id) |>
  summarize(across(everything(), sum)) -> zz

zz2 <- gene_cnts |>
  arrange(gene_id) |>
  filter(gene_id %in% zz$gene_id)

# waldo::compare(zz, zz2, ignore_attr = TRUE)
all.equal(zz,zz2, check.attributes = FALSE) |> head()

waldo::compare(zz |>
                 filter(! gene_id %in% s2i(c("tin-9.2","exos-4.1","unc-17","cha-1","lev-10","eat-18"),gids)),
               zz2 |>
                 filter(! gene_id %in% s2i(c("tin-9.2","exos-4.1","unc-17","cha-1","lev-10","eat-18"),gids)))

all.equal(zz |>
            filter(! gene_id %in% s2i(c("tin-9.2","exos-4.1","unc-17","cha-1","lev-10","eat-18"),gids)),
               zz2 |>
            filter(! gene_id %in% s2i(c("tin-9.2","exos-4.1","unc-17","cha-1","lev-10","eat-18"),gids)),
          check.attributes = FALSE)
#> so the tx and gene-level counts are equivalent, except for those genes that are on top of each other




# Make sample table ----
samples_table <- cnts_long |>
  group_by(sample_id) |>
  summarize(tot_reads = sum(count),
            .groups = "drop") |>
  mutate(neuron_id = str_match(sample_id, "^([A-Zef0-9]{1,4})r[0-9]{1,3}$")[,2])





str_match(colnames(cnts), "^([A-Z0-9]{1,4}|Ref)r[0-9]{1,4}$") %>%
  as_tibble(.name_repair = "universal") %>%
  dplyr::slice(-1) %>%
  dplyr::rename(sample_id = ...1,
                neuron = ...2) %>%
  arrange(sample_id) %>%
  identical(samples_table %>% select(-replicate)) %>%
  stopifnot()


# rename genes and transcripts
cnts <- cnts |>
  left_join(tx_lut,
            by = c(transcript_id = "tx_id"))

cnts_long  <- cnts |>
  pivot_longer(-c("transcript_id","gene_id","tx_name"),
               names_to = "sample_id") |>
  mutate(neuron = str_match(sample_id,"^([A-Zef0-9]{2,4})r\\d{1,3}$")[,2])

# saveRDS(cnts_long, "data/intermediates_visualization/210910_cnts_long.rds")


#~ Count reads ----

candidates <- read_tsv("data/intermediates_visualization/candidates.txt",
                       col_names = "gene_name", col_types = "c")


cmat <- as.matrix(cnts[,2:170])

left_join(candidates |> 
            mutate(gene_id = s2i(gene_name, gids)),
          tibble(gene_id   = cnts$gene_id,
                 sum_count = apply(cmat, 1, sum)/1e5) |> 
            group_by(gene_id) |>
            summarize(sum_count = sum(sum_count))) |>
  pull(sum_count) |>
  clipr::write_clip()


#~ Count genes with AS ----

# Keep protein-coding, multi-exon genes
gids |> 
  filter(biotype == "protein_coding_gene")

exons <- wb_load_exon_coords(277)

ex_per_gene <- exons |>
  group_by(gene_id) |>
  summarize(nb_exons = n(),
            biotype = first(gene_biotype))

multi_ex_pcd <- ex_per_gene |> 
  filter(nb_exons > 1,
         biotype == "protein_coding") |> 
  pull(gene_id)

# Find single-isoform genes
isof_per_gene <- cnts_long |> 
  group_by(gene_id) |>
  summarize(nb_isof = n_distinct(tx_name))
list_single_isof_genes <- isof_per_gene |>
  filter(nb_isof < 2) |>
  pull(gene_id)

# Find usage of major/minor isoforms
cnts_sample_prop <- cnts_long |>
  filter(! gene_id %in% list_single_isof_genes,
         gene_id %in% multi_ex_pcd) |>
  group_by(gene_id, sample_id) |>
  mutate(prop_sample = value/sum(value)) |>
  filter(! is.na(prop_sample))

cnts_neuron_mean <- cnts_sample_prop |>
  group_by(gene_id, tx_name, neuron) |>
  summarize(prop = mean(prop_sample),
            sd = sd(prop_sample),
            .groups = "drop")

cnts_major_minor_isoform <- cnts_neuron_mean |>
  group_by(gene_id, tx_name) |>
  summarize(max_prop = max(prop),
            .groups = "drop") |>
  group_by(gene_id) |>
  summarize(prop_highest = max(max_prop),
            prop_second = sort(max_prop, decreasing = TRUE)[[2]])

hist(cnts_major_minor_isoform$prop_highest, breaks = 100)
nrow(cnts_major_minor_isoform)
table(cnts_major_minor_isoform$prop_second > .15)
# as per Wang (2008), count a gene AS if minor isof > 15%
# https://www.nature.com/articles/nature07509

# Just protein-coding genes

cnts_long |> select(gene_id) |> distinct() |> left_join(gids) |> pull(biotype) |> table()
#> 19,995 prot-coding genes in data
left_join(cnts_major_minor_isoform, gids, by = "gene_id") |>
  filter(biotype == "protein_coding_gene") |>
  pull(prop_second) %>%
  {table(. > .15)}
#> 6,175 of the prot-coding genes have minor isof > 15%



